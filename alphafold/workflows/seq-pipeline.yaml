# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.
# [START workflows_batch_primegen]
main:
  params: [args]
  steps:
    - init:
        assign:
          - projectId: ${sys.get_env("GOOGLE_CLOUD_PROJECT_ID")}
          - imageUri: ${"gcr.io/" + projectId + "/alphafold"}
          - region: "us-central1"
          - jobId: ${"job-alphafold-" + string(int(sys.now()))}
          - jobPath: ${args.stagingLocation + "/" + jobId}
          - modelParamsPath: "jk-alphafold-datasets-archive/v2.2.0" 
          - modelPreset: "monomer"
          - runRelax: true
    - callDataPipeline:
        call: runDataPipeline
        args:
          fastaSequence: ${args.fastaSequence}
          maxTemplateDate: ${args.maxTemplateDate}
          jobId: ${jobId}
          jobPath: ${jobPath}
          refDBsDisk: ${args.refDBsDisk}
          modelPreset: ${args.modelPreset}
          dbPreset: ${args.dbPreset}
          imageUri: ${imageUri}
          region: ${region}
          projectId: ${projectId}
        result: dataPipelineOutput
    - logDataPipelineOutput:
        call: sys.log
        args:
          data: ${dataPipelineOutput}
    - callPredictRelax:
        call: runPredictRelax
        args:
          jobPath: ${dataPipelineOutput.jobPath}
          jobId: ${jobId}
          modelParamsPath: ${args.modelParamsPath} 
          modelPreset: ${args.modelPreset} 
          runRelax: ${args.runRelax} 
          imageUri: ${imageUri}
          region: ${region}
          projectId: ${projectId}

# Subworkflows
runDataPipeline:
  params: [fastaSequence, modelPreset, dbPreset, maxTemplateDate, jobId, jobPath, refDBsDisk,  imageUri, projectId, region]
  steps:
    - init:
        assign:
          - batchJobId: ${jobId + "-data-pipeline"}
          - batchApi: "batch.googleapis.com/v1"
          - batchApiUrl: ${"https://" + batchApi + "/projects/" + projectId + "/locations/" + region + "/jobs"}
          - machineTypeCPU: "c2-standard-16"
          - cpuMilli: 14000
          - memoryMib: 40000
          - maxRetryCount: 2
          - maxRunDuration: "7200s"
          - fastaBucket: ${text.split(fastaSequence, "/")[0]}
          - fastaObject: ${text.substring(fastaSequence, len(fastaBucket) + 1, len(fastaSequence))}
          - jobBucket: ${text.split(jobPath, "/")[0]}
          - jobDir: ${text.substring(jobPath, len(jobBucket) + 1, len(jobPath))}
    - returnMock:
        return:
          jobId: ${jobId}
          jobPath: "jk-alphafold-staging/batch-jobs/job-alphafold-1667782536" 
    - logDebug:
        call: sys.log
        args:
          data: ${"Running data pipeline on:" + "gs://" + fastaBucket + "/" + fastaObject} 
    - copySequence:
        call: googleapis.storage.v1.objects.copy
        args:
            destinationBucket: ${text.url_encode(jobBucket)} 
            destinationObject: ${text.url_encode(jobDir + "/" + "sequence.fasta")}
            sourceBucket: ${text.url_encode(fastaBucket)}
            sourceObject: ${text.url_encode(fastaObject)}
    - runDataPipelineCloudBatchJob:
        call: http.post
        args:
          url: ${batchApiUrl}
          query:
            job_id: ${batchJobId}
          headers:
            Content-Type: application/json
          auth:
            type: OAuth2
          body:
            taskGroups:
              taskSpec:
                runnables:
                  - container:
                      imageUri: ${imageUri}
                      entrypoint: "python"
                      commands:
                        - "/runners/run_data_pipeline.py"
                        - "--ref_dbs_mount_path=/mnt/disks/ref_dbs"
                        - "--fasta_path=/mnt/disks/job_dir/sequence.fasta"
                        - ${"--max_template_date=" + maxTemplateDate}
                        - ${"--model_preset=" + modelPreset}
                        - ${"--db_preset=" + dbPreset}
                        - "--output_path=/mnt/disks/job_dir"
                volumes:
                  - deviceName: "databases"
                    mountPath: "/mnt/disks/ref_dbs"
                  - gcs:
                      remotePath: ${jobPath + "/"}
                    mountPath: "/mnt/disks/job_dir"
                computeResource:
                  cpuMilli: ${cpuMilli} 
                  memoryMib: ${memoryMib}
                maxRetryCount: ${maxRetryCount}
                maxRunDuration: ${maxRunDuration}
              taskCount: 1
              parallelism: 1
            allocationPolicy:
              instances:
                - policy:
                    machineType: ${machineTypeCPU}
                    disks:
                      - deviceName: "databases"
                        existingDisk: ${refDBsDisk}
            logsPolicy:
              destination: CLOUD_LOGGING
        result: createAndRunBatchJobResponse
    - getJob:
        call: http.get
        args:
          url: ${batchApiUrl + "/" + batchJobId}
          auth:
            type: OAuth2
        result: getJobResult
    - logState:
        call: sys.log
        args:
          data: ${"Current job state " + getJobResult.body.status.state}
    - checkState:
        switch:
          - condition: ${getJobResult.body.status.state == "SUCCEEDED"}
            next: returnResult
          - condition: ${getJobResult.body.status.state == "FAILED"}
            next: failExecution 
        next: sleep
    - sleep:
        call: sys.sleep
        args:
          seconds: 10
        next: getJob
    - returnResult:
        return:
          jobPath: ${jobPath}
    - failExecution:
        raise:
          message: ${"The underlying batch job " + batchJobId + " failed"}

runPredictRelax:
  params: [jobPath, jobId, modelParamsPath, modelPreset, runRelax, imageUri, projectId, region, randomSeed: Null]
  steps:
    - init:
        assign:
          - batchJobId: ${jobId + "-predict-relax"}
          - batchApi: "batch.googleapis.com/v1"
          - batchApiUrl: ${"https://" + batchApi + "/projects/" + projectId + "/locations/" + region + "/jobs"}
          - machineTypeGPU: "n1-standard-8"
          - gpuType: "nvidia-tesla-t4"
          - gpuCount: 1
          - cpuMilli: 8000
          - memoryMib: 30000
          - maxRetryCount: 2
          - maxRunDuration: "7200s"
    - logInputs:
        call: sys.log
        args:
          data: ${jobPath + " " + modelParamsPath}
    - runPredictRelaxCloudBatchJob: 
        call: http.post
        args:
          url: ${batchApiUrl}
          query:
            job_id: ${batchJobId}
          headers:
            Content-Type: application/json
          auth:
            type: OAuth2
          body:
            taskGroups:
              taskSpec:
                runnables:
                  - container:
                      imageUri: ${imageUri}
                      entrypoint: "python"
                      commands:
                        - "/runners/run_predict_relax.py"
                        - "--job_path=/mnt/disks/job_dir"
                        - "--model_params_path=/mnt/disks/params"
                        - ${"--model_preset=" + modelPreset}
                        - ${if(randomSeed, "--random_seed=" + string(randomSeed), "")}
                      options: "--privileged"
                      volumes:
                        - "/var/lib/nvidia/lib64:/usr/local/nvidia/lib64"
                        - "/var/lib/nvidia/bin:/usr/local/nvidia/bin"
                        - "/mnt/disks/params:/mnt/disks/params"
                        - "/mnt/disks/job_dir:/mnt/disks/job_dir"
                volumes:
                  - gcs: 
                      remotePath: ${modelParamsPath + "/"}
                    mountPath: "/mnt/disks/params"
                  - gcs:
                      remotePath: ${jobPath + "/"}
                    mountPath: "/mnt/disks/job_dir"
                computeResource:
                  cpuMilli: ${cpuMilli} 
                  memoryMib: ${memoryMib}
                maxRetryCount: ${maxRetryCount}
                maxRunDuration: ${maxRunDuration}
              taskCount: 1
              parallelism: 1
            allocationPolicy:
              instances:
                - policy:
                    machineType: ${machineTypeGPU}
                    accelerators:
                      - type: ${gpuType}
                        count: ${gpuCount}
                  installGpuDrivers: true

            logsPolicy:
              destination: CLOUD_LOGGING
        result: createAndRunBatchJobResponse
    - getJob:
        call: http.get
        args:
          url: ${batchApiUrl + "/" + batchJobId}
          auth:
            type: OAuth2
        result: getJobResult
    - logState:
        call: sys.log
        args:
          data: ${"Current job state " + getJobResult.body.status.state}
    - checkState:
        switch:
          - condition: ${getJobResult.body.status.state == "SUCCEEDED"}
            next: returnResult
          - condition: ${getJobResult.body.status.state == "FAILED"}
            next: failExecution 
        next: sleep
    - sleep:
        call: sys.sleep
        args:
          seconds: 10
        next: getJob
    - returnResult:
        return:
          jobPath: ${jobPath}
    - failExecution:
        raise:
          message: ${"The underlying batch job " + batchJobId + " failed"}
