# Copyright 2022 Google LLC
#
# Licensed under the Apache License, Version 2.0 (the "License");
# you may not use this file except in compliance with the License.
# You may obtain a copy of the License at
#
#     http://www.apache.org/licenses/LICENSE-2.0
#
# Unless required by applicable law or agreed to in writing, software
# distributed under the License is distributed on an "AS IS" BASIS,
# WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.
# See the License for the specific language governing permissions and
# limitations under the License.

main:
  params: [args]
  steps:
    - init:
        assign:
          - supportedMachineConfigs: {}
          - supportedMachineConfigs["c2-standard-16"]:
                machineType: "c2-standard-16"
                cpuMilli: 16000
                memoryMib: 64000
                bootDiskMib: 200000
          - supportedMachineConfigs["c2-standard-30"]:
                machineType: "c2-standard-30"
                cpuMilli: 30000
                memoryMib: 120000
                bootDiskMib: 200000
          - supportedMachineConfigs["n1-standard-8-t4"]:
                machineType: "n1-standard-8"
                cpuMilli: 8000
                memoryMib: 30000
                bootDiskMib: 200000
                gpuType: "nvidia-tesla-t4"
                gpuCount: 1
          - supportedMachineConfigs["a2-highgpu-1g"]:
                machineType: "a2-highgpu-1g"
                cpuMilli: 12000
                memoryMib: 85000
                bootDiskMib: 200000
                gpuType: "nvidia-tesla-a100"
                gpuCount: 1
          - dataPipelineMachineConfig: ${default(map.get(supportedMachineConfigs, args.dataPipelineMachineType), supportedMachineConfigs["c2-standard-16"])}
          - predictRelaxMachineConfig: ${default(map.get(supportedMachineConfigs, args.predictRelaxMachineType), supportedMachineConfigs["n1-standard-8-t4"])}

    - callDataPipeline:
        call: runDataPipeline
        args:
          machineConfig: ${dataPipelineMachineConfig}
          args: args
        result: dataPipelineOutput

    - callPredictRelax:
        call: runPredictRelax
        args:
          machineConfig: ${predictRelaxMachineConfig} 
          args: args
        result: predictRelaxResult


runDataPipeline:
  params: [machineConfig, args]
  steps:
    - init:
        assign:
          - batchJobId: ${args.job_id + "-data-pipeline"}
          - batchApi: "batch.googleapis.com/v1"
          - batchApiUrl: ${"https://" + batchApi + "/projects/" + args.project_id + "/locations/" + args.region + "/jobs"}
          - maxRetryCount: 2
          - maxRunDuration: "7200s"
          - refDbsMountPath: "/mnt/disks/ref_dbs"
          - jobDirMountPath: "/mnt/disks/job_dir"
          - inputDirMountPath: "/mnt/disks/input"
    - runDataPipelineCloudBatchJob:
        call: http.post
        args:
          url: ${batchApiUrl}
          query:
            job_id: ${batchJobId}
          headers:
            Content-Type: application/json
          auth:
            type: OAuth2
          body:
            taskGroups:
              taskSpec:
                runnables:
                  - container:
                      imageUri: ${args.image_uri}
                      entrypoint: "python"
                      commands:
                        - "/runners/run_data_pipeline.py"
                        - ${"--fasta_input_path=" + inputDirMountPath + "/" + args.blob_sequence_path}
                        - ${"--msas_output_path=" + jobDirMountPath + "/" + args.msas_folder}
                        - ${"--features_output_path=" + jobDirMountPath + "/" + args.data_features_filename}
                        - ${"--metadata_output_path=" + jobDirMountPath + "/" + args.data_metadata_filename}
                        - ${"--ref_dbs_root_path=" + refDbsMountPath}
                        - ${"--db_preset=" + args.db_preset}
                        - ${"--model_preset=" + args.model_preset}
                        - ${"--max_template_date=" + args.max_templateDate}
                volumes:
                  - nfs: 
                      server: ${args.nfs_ip_address}
                      remotePath: ${args.nfs_path}
                    mountPath: ${refDbsMountPath}
                  - gcs:
                      remotePath: ${args.gcs_job_path}
                    mountPath: ${jobDirMountPath}
                  - gcs:
                      remotePath: ${args.bucket_name}
                    mountPath: ${inputDirMountPath}
                computeResource:
                  cpuMilli: ${machineConfig.cpuMilli} 
                  memoryMib: ${machineConfig.memoryMib}
                  bootDiskMib: ${machineConfig.bootDiskMib}
                maxRetryCount: ${maxRetryCount}
                maxRunDuration: ${maxRunDuration}
              taskCount: 1
              parallelism: 1
            allocationPolicy:
              instances:
                - policy:
                    machineType: ${machineConfig.machineType}
              network:
                networkInterfaces:
                  - network: ${args.network}
                    subnetwork: ${args.subnetwork}
            logsPolicy:
              destination: CLOUD_LOGGING
        result: createAndRunBatchJobResponse
    - getJob:
        call: http.get
        args:
          url: ${batchApiUrl + "/" + batchJobId}
          auth:
            type: OAuth2
        result: getJobResult
    - logState:
        call: sys.log
        args:
          data: ${"Current job state " + getJobResult.body.status.state}
    - checkState:
        switch:
          - condition: ${getJobResult.body.status.state == "SUCCEEDED"}
            next: returnResult 
          - condition: ${getJobResult.body.status.state == "FAILED"}
            next: failExecution 
        next: sleep
    - sleep:
        call: sys.sleep
        args:
          seconds: 10
        next: getJob
    - returnResult:
        return:
          featuresFilePath: ${args.gcs_job_path + "/" + args.data_features_filename}
          metadataFilePath: ${args.gcs_job_path + "/" + args.data_metadata_filename}
    - failExecution:
        raise:
          message: ${"The underlying batch job " + batchJobId + " failed"}


runPredictRelax:
  params: [machineConfig, args]
  steps:
    - init:
        assign:
          - batchApi: "batch.googleapis.com/v1"
          - batchApiUrl: ${"https://" + batchApi + "/projects/" + args.project_id + "/locations/" + args.region + "/jobs"}
          - maxRetryCount: 2
          - maxRunDuration: "7200s"
          - numModels: 5
          - jobDirMountPath: "/mnt/disks/job_dir"
          - featuresDirMountPath: "/mnt/disks/features"
          - modelParamsMountPath: "/mnt/disks/params"
          - jobResults: []
    - runPredictRelaxCloudBatchJobs: 
        parallel:
          concurrency_limit: ${args.parallelism}
          shared: [jobResults]
          for:
            value: runnerIndex
            range: ${[0, numModels * args.num_predictions_per_model - 1]}
            steps:
              - initParams:
                  assign:
                    - batchJobId: ${args.job_id + "-predict-relax-" + runnerIndex}
                    - modelIndex: ${runnerIndex // args.num_predictions_per_model}
                    - predictionIndex: ${runnerIndex % args.num_predictions_per_model}
                    - predictionRandomSeed: ${args.random_seed + runnerIndex}
                    - rawPredictionPath: ${jobDirMountPath +  "/result_model_" + modelIndex + "_pred_" + predictionIndex + ".pkl" }
                    - unrelaxedProteinPath: ${jobDirMountPath +  "/unrelaxed_model_" + modelIndex + "_pred_" + predictionIndex + ".pdb"}
                    - relaxedProteinPath: ${jobDirMountPath +  "/relaxed_model_" + modelIndex + "_pred_" + predictionIndex + ".pdb"}
                    - predictionMetadataPath: ${jobDirMountPath + "/pred_metadata_model_" + modelIndex + "_pred_" + predictionIndex + ".json"}
                    - relaxationMetadataPath: ${jobDirMountPath + "/relax_metadata_model_" + modelIndex + "_pred_" + predictionIndex + ".json"}
              - logJobStart:
                  call: sys.log
                  args:
                    data: ${"Starting job " + batchJobId + " Concurrency level is " + parallelism}
              - startBatchJob:
                  call: http.post
                  args:
                    url: ${batchApiUrl}
                    query:
                      job_id: ${batchJobId}
                    headers:
                      Content-Type: application/json
                    auth:
                      type: OAuth2
                    body:
                      taskGroups:
                        taskSpec:
                          runnables:
                            - container:
                                imageUri: ${args.image_uri}
                                entrypoint: "python"
                                commands:
                                  - "/runners/run_predict.py"
                                  - ${"--input_features_path=" + featuresDirMountPath + "/" + args.blob_data_features_path}
                                  - ${"--model_params_path=" + modelParamsMountPath}
                                  - ${"--metadata_output_path=" + predictionMetadataPath}
                                  - ${"--raw_prediction_path=" + rawPredictionPath}
                                  - ${"--unrelaxed_protein_path=" + unrelaxedProteinPath}
                                  - ${"--model_preset=" + args.model_preset}
                                  - ${"--model_index=" + modelIndex}
                                  - ${"--prediction_index=" + predictionIndex}
                                  - ${"--random_seed=" + predictionRandomSeed}
                                options: "--privileged"
                                volumes:
                                  - "/var/lib/nvidia/lib64:/usr/local/nvidia/lib64"
                                  - "/var/lib/nvidia/bin:/usr/local/nvidia/bin"
                                  - ${modelParamsMountPath + ":" + modelParamsMountPath}
                                  - ${jobDirMountPath + ":" + jobDirMountPath}
                                  - ${featuresDirMountPath + ":" + featuresDirMountPath}
                            - container:
                                imageUri: ${args.image_uri}
                                entrypoint: "python"
                                commands:
                                  - "/runners/run_relax.py"
                                  - ${"--unrelaxed_protein_path=" + unrelaxedProteinPath}
                                  - ${"--relaxed_protein_path=" + relaxedProteinPath}
                                  - ${"--metadata_output_path=" + relaxationMetadataPath}
                                  - ${"--unrelaxed_protein_path=" + unrelaxedProteinPath}
                                  - ${if(args.run_relax, "--run_relax", "norun_relax")}
                                options: "--privileged"
                                volumes:
                                  - "/var/lib/nvidia/lib64:/usr/local/nvidia/lib64"
                                  - "/var/lib/nvidia/bin:/usr/local/nvidia/bin"
                                  - ${jobDirMountPath + ":" + jobDirMountPath}
                          volumes:
                            - gcs: 
                                remotePath: ${args.model_params_path}
                              mountPath: ${modelParamsMountPath}
                            - gcs:
                                remotePath: ${args.gcs_job_path}
                              mountPath: ${jobDirMountPath}
                            - gcs:
                                remotePath: ${args.bucket_name}
                              mountPath: ${featuresDirMountPath}
                          computeResource:
                            cpuMilli: ${machineConfig.cpuMilli} 
                            memoryMib: ${machineConfig.memoryMib}
                            bootDiskMib: ${machineConfig.bootDiskMib}
                          maxRetryCount: ${maxRetryCount}
                          maxRunDuration: ${maxRunDuration}
                        taskCount: 1 
                      allocationPolicy:
                        instances:
                          - policy:
                              machineType: ${machineConfig.machineType}
                              accelerators:
                                - type: ${machineConfig.gpuType}
                                  count: ${machineConfig.gpuCount}
                            installGpuDrivers: true

                      logsPolicy:
                        destination: CLOUD_LOGGING
                  result: createAndRunBatchJobResponse
              - getJob:
                  call: http.get
                  args:
                    url: ${batchApiUrl + "/" + batchJobId}
                    auth:
                      type: OAuth2
                  result: getJobResult
              - logState:
                  call: sys.log
                  args:
                    data: ${"Current job state for job  " + batchJobId + " is " + getJobResult.body.status.state}
              - checkState:
                  switch:
                    - condition: ${getJobResult.body.status.state == "SUCCEEDED"}
                      next: returnResult
                    - condition: ${getJobResult.body.status.state == "FAILED"}
                      next: returnResult 
                  next: sleep
              - sleep:
                  call: sys.sleep
                  args:
                    seconds: 10
                  next: getJob
              - returnResult:
                  assign:
                    - jobResults: ${list.concat(jobResults, getJobResult)}
                    
    - monitorJobs:
        call: sys.log
        args:
          data: ${jobResults}